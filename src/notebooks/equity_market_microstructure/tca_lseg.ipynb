{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T01:14:32.611410Z",
     "iopub.status.busy": "2024-03-05T01:14:32.610318Z",
     "iopub.status.idle": "2024-03-05T01:14:52.653326Z",
     "shell.execute_reply": "2024-03-05T01:14:52.653181Z",
     "shell.execute_reply.started": "2024-03-05 01:14:32.615464+00:00"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%configure -f\n",
    "{ \"conf\":{\n",
    "     \"spark.pyspark.python\": \"python3\"\n",
    "    ,\"spark.pyspark.virtualenv.enabled\": \"true\"\n",
    "    ,\"spark.kubernetes.executor.node.selector.node-lifecycle\":\"spot\"\n",
    "    ,\"spark.pyspark.virtualenv.type\":\"native\"\n",
    "    ,\"spark.pyspark.virtualenv.bin.path\":\"/usr/bin/virtualenv\"\n",
    "    ,\"spark.sql.files.ignoreCorruptFiles\":\"true\"\n",
    "    ,\"spark.dynamicAllocation.executorIdleTimeout\":\"18000\"\n",
    "    ,\"spark.driver.memory\":\"32g\"\n",
    "    ,\"spark.driver.cores\":\"32\"\n",
    "    ,\"spark.driver.maxResultSize\":\"24g\"\n",
    "    ,\"spark.executor.memory\":\"32g\"\n",
    "    ,\"spark.network.timeout\":\"300\"\n",
    "    ,\"spark.executor.cores\":\"8\"\n",
    "    ,\"spark.dynamicAllocation.maxExecutors\":\"500\"\n",
    "    ,\"livy.server.session.timeout\":\"24h\"\n",
    "    ,\"spark.sql.shuffle.partitions\":\"15000\"\n",
    "    ,\"spark.driver.extraJavaOptions\":\"-DPYARROW_IGNORE_TIMEZONE:1\"\n",
    "    ,\"spark.executor.extraJavaOptions\":\"-DPYARROW_IGNORE_TIMEZONE:1\"\n",
    "    }\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T01:19:01.249023Z",
     "iopub.status.busy": "2024-03-05T01:19:01.248033Z",
     "iopub.status.idle": "2024-03-05T01:21:56.505873Z",
     "shell.execute_reply": "2024-03-05T01:21:56.504596Z",
     "shell.execute_reply.started": "2024-03-05T01:19:01.248977Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "import pyspark.sql.types as t\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "s3_path='s3://maystreetdata/feeds_norm/mstnorm_parquet_0_5_0/'\n",
    "s3_working_dir='s3://maystreetdata/analysis/'\n",
    "# col('ReceiptTimestamp') is in nano seconds in UTC timezone so we convert it to unix timestamp in exchange timezone\n",
    "# keeping first 10 digits and then convert it pySpark timestamp, \n",
    "f_hour_from_ns_ts= f.from_utc_timestamp(f.from_unixtime(f.col('ReceiptTimestamp').cast(t.StringType())[0:10]),'America/New_York').cast(t.StringType())[12:2]\n",
    "select_cols = ['f','Feed','SequenceNumber','Product','ReceiptTimestamp','dt']\n",
    "nbbo_df= spark.read.parquet(f'{s3_path}mt=nbbo_quote/').select(select_cols+['BidPrice','BidQuantity','AskPrice','AskQuantity']).withColumn('dtHour', f_hour_from_ns_ts)\n",
    "trade_df= spark.read.parquet(f'{s3_path}mt=trade/').select(select_cols+['Price','Quantity','Side','OrderReferenceNumber','LeavesQuantity']).withColumn('dtHour', f_hour_from_ns_ts)\n",
    "order_df= spark.read.parquet(f'{s3_path}mt=add_order/').select(select_cols+['Price','Quantity','Side','OrderReferenceNumber']).withColumn('dtHour', f_hour_from_ns_ts)\n",
    "one_mill_const = 1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ORDERS SECTION ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T01:21:56.509001Z",
     "iopub.status.busy": "2024-03-05T01:21:56.508469Z",
     "iopub.status.idle": "2024-03-05T01:26:32.080795Z",
     "shell.execute_reply": "2024-03-05T01:26:32.079383Z",
     "shell.execute_reply.started": "2024-03-05T01:21:56.508961Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculate trade volume and number of orders per exchange\n",
    "order_df.groupBy(['feed','f']).agg((f.sum(f.col('Quantity') * f.col('Price'))/f.lit(one_mill_const)).cast('float').alias(\"DollarVolume(Million)\"),\n",
    "                           f.count('SequenceNumber').alias(\"NumOfOrders\")).orderBy(['feed','f']).pandas_api()\\\n",
    ".style.format(thousands=',',precision=0).background_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T01:26:32.083822Z",
     "iopub.status.busy": "2024-03-05T01:26:32.082596Z",
     "iopub.status.idle": "2024-03-05T01:33:39.342148Z",
     "shell.execute_reply": "2024-03-05T01:33:39.340973Z",
     "shell.execute_reply.started": "2024-03-05T01:26:32.083778Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# below we calculate the following metrics grouped per hour\n",
    "# trade volume and number of orders per exchangetrade volume and number of orders per hour across all exchanges\n",
    "order_df_analysis = order_df\\\n",
    ".groupBy(['dtHour']).agg(\n",
    "     f.countDistinct('OrderReferenceNumber').alias(\"NumOfOrders\"),\n",
    "    f.round(f.sum(f.col('Quantity') * f.col('Price'))/f.lit(one_mill_const),0).cast('float').alias(\"DollarVolume(Million)\"),\n",
    "    (f.avg(f.when(f.col('Side')=='Bid', (f.col('Quantity') * f.col('Price'))).otherwise(None))/f.lit(1)).cast('float').alias(\"AvgDollarVolume_Bid\"),\n",
    "    (f.avg(f.when(f.col('Side')=='Ask', (f.col('Quantity') * f.col('Price'))).otherwise(None))/f.lit(1)).cast('float').alias(\"AvgDollarVolume_Ask\"),\n",
    "                        ).orderBy(['dtHour'])#.cache()\n",
    "\n",
    "order_df_analysis.pandas_api().style.format(thousands=',',precision=0).background_gradient()\n",
    "\n",
    "# what you need to do:\n",
    "# calculate the overall trading volume for work hours vs after-hours \n",
    "# calculating distinct values over high-cardinality column may be expensive, you can try calcualting approximate distinct count and see what performance improvements it brings.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T01:33:39.344934Z",
     "iopub.status.busy": "2024-03-05T01:33:39.344561Z",
     "iopub.status.idle": "2024-03-05T01:36:35.878330Z",
     "shell.execute_reply": "2024-03-05T01:36:35.877087Z",
     "shell.execute_reply.started": "2024-03-05T01:33:39.344896Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot line graph based on spark query results using seaborn\n",
    "#import seaborn as sns\n",
    "#sns.set_theme()\n",
    "#ax = sns.relplot(\n",
    "#    data=order_df_analysis.select('dtHour','DollarVolume').withColumn('DollarVolume(millions)',f.col('DollarVolume')/1000000).orderBy('dtHour').toPandas(), \n",
    "#    height=3, aspect=3.5, kind='line',\n",
    "#    x=\"dtHour\", y=\"DollarVolume(millions)\"\n",
    "#) \n",
    "order_df_analysis.pandas_api().set_index('dtHour')[['DollarVolume(Million)']].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T13:15:26.523331Z",
     "iopub.status.busy": "2024-03-04T13:15:26.522506Z",
     "iopub.status.idle": "2024-03-04T13:20:29.437038Z",
     "shell.execute_reply": "2024-03-04T13:20:29.435905Z",
     "shell.execute_reply.started": "2024-03-04T13:15:26.523280Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot line graph based on spark query results using pyspark pandas\n",
    "#using pyspark pandas is preferred over toPandas() method that copies all data to the driver node. \n",
    "order_df_analysis.select('dtHour','AvgDollarVolume_Bid','AvgDollarVolume_Ask')\\\n",
    ".orderBy('dtHour').pandas_api().set_index(\"dtHour\").plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T13:20:29.438786Z",
     "iopub.status.busy": "2024-03-04T13:20:29.438453Z",
     "iopub.status.idle": "2024-03-04T13:20:29.717530Z",
     "shell.execute_reply": "2024-03-04T13:20:29.716279Z",
     "shell.execute_reply.started": "2024-03-04T13:20:29.438749Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get some individual tickers to analyse\n",
    "sample_tickers=['AMZN','MSFT','GS','GE']\n",
    "# calculate daily volumes for those tickers\n",
    "plot_df = order_df.filter(order_df.Product.isin(sample_tickers)).select(\n",
    "    f.col('dtHour'),'dt', 'Product', 'Quantity', 'Price','f','Feed')\\\n",
    "    .groupBy('dt','dtHour','Product','f','Feed')\\\n",
    "    .agg(f.sum(f.col('Quantity')*f.col('Price')/f.lit(one_mill_const)).alias('DollarVolume(Millions)')\n",
    ").cache()\n",
    "\n",
    "#calculate percentage of stock's volume on given exchange vs total volume on all exchanges(Feed) per hour of the day\n",
    "plot_df=plot_df.withColumn('Percent',  \n",
    "    (100*f.col('DollarVolume(Millions)'))/f.sum('DollarVolume(Millions)').over(Window.partitionBy(['dt','dtHour','Product']))\n",
    ")\n",
    "\n",
    "#calculate percentage of stock's volume on given exchange per hour across all days vs total stock volume on all exchanges(Feed) per hour across all days\n",
    "plot_df=plot_df.withColumn('PercentHour',  \n",
    "    (100*f.sum('DollarVolume(Millions)').over(Window.partitionBy(['dtHour','Product','Feed'])))/f.sum('DollarVolume(Millions)').over(Window.partitionBy(['dtHour','Product']))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T13:20:29.719642Z",
     "iopub.status.busy": "2024-03-04T13:20:29.719035Z",
     "iopub.status.idle": "2024-03-04T13:20:58.586966Z",
     "shell.execute_reply": "2024-03-04T13:20:58.585601Z",
     "shell.execute_reply.started": "2024-03-04T13:20:29.719601Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_pd = plot_df.toPandas()\n",
    "#convertion to pandas looses schema, so need to reset the types\n",
    "plot_pd['DollarVolume(Millions)']=plot_pd['DollarVolume(Millions)'].astype('float');\n",
    "plot_pd['PercentHour']=plot_pd['PercentHour'].astype('float');\n",
    "plot_pd['Product']=plot_pd['Product'].astype('string');\n",
    "plot_pd['dt']=plot_pd['dt'].astype('string');\n",
    "plot_pd['dtHour']=plot_pd['dtHour'].astype('string');\n",
    "\n",
    "plot_pd_wide =pd.pivot_table(plot_pd, values='PercentHour', index=['dtHour'],\n",
    "                       columns=['Product','Feed']).fillna(0)\n",
    "plot_pd_wide.style.format(thousands=',',precision=0).background_gradient(axis=0)\n",
    "#BL: graph it as stacked bars to easily visualize exchange market share would be good visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T13:20:58.589342Z",
     "iopub.status.busy": "2024-03-04T13:20:58.588693Z",
     "iopub.status.idle": "2024-03-04T13:21:01.048038Z",
     "shell.execute_reply": "2024-03-04T13:21:01.046887Z",
     "shell.execute_reply.started": "2024-03-04T13:20:58.589302Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#generate visual using built-in pandas integration with matplotlib\n",
    "# we use toPandas() here \n",
    "for one_t in sample_tickers:\n",
    "    plot_pd.query(f\"Product=='{one_t}'\").pivot_table(index=[\"dtHour\"], columns=[\"Feed\"],values=\"DollarVolume(Millions)\")\\\n",
    "    .plot(title=f\"{one_t}\",kind=\"bar\", stacked='True', ylabel=\"DollarVolume(Millions)\", figsize=(6, 3))\n",
    "\n",
    "#BL: broke this by adding one more field - tried to fix it but gave up since i rarely use seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRADES SECTION ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T03:55:57.942181Z",
     "iopub.status.busy": "2024-03-05T03:55:57.941534Z",
     "iopub.status.idle": "2024-03-05T03:55:58.056130Z",
     "shell.execute_reply": "2024-03-05T03:55:58.054908Z",
     "shell.execute_reply.started": "2024-03-05T03:55:57.942140Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cover for order partial refills, replacing price with vwap price and timestamp with the latest filled part of the order\n",
    "#we also make sure we only look for the fully filled orders, last LeavesQuantity=0 \n",
    "trade_df_grouped = trade_df.groupBy('OrderReferenceNumber','Product','Side','Feed','f',\"dtHour\",'dt').agg(\n",
    "    f.sum(f.col('Quantity')).alias('Quantity'),\n",
    "    f.sum(f.col('Quantity') * f.col('Price')).alias('TradeSizeUsd'),\n",
    "    f.min('ReceiptTimestamp').alias('ReceiptTimestamp'),\n",
    "    f.last(f.col('LeavesQuantity'),True).alias('Unfilled')\n",
    ").withColumn('vWAP',f.col('TradeSizeUsd')/f.col('Quantity')).filter(f.col('Unfilled')<1).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T03:55:58.638393Z",
     "iopub.status.busy": "2024-03-05T03:55:58.637749Z",
     "iopub.status.idle": "2024-03-05T03:58:40.261475Z",
     "shell.execute_reply": "2024-03-05T03:58:40.260253Z",
     "shell.execute_reply.started": "2024-03-05T03:55:58.638353Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#verify that calculation is correct\n",
    "#\n",
    "#BL: order hits the order book few minutes before the fill, so the timestamp and MID price has to be calculated using thisd time. if you use join need to join on [OrderReferenceNumber,Product, Side, f, Feed] \n",
    "#BL: as orderRefNums are unique only per day within scope of single feed/f/product. technically not product but within single session but since we dont know how their shard sessions we need to join on all columns\n",
    "order_df.where(\"OrderReferenceNumber=='1000045252' and Product=='SSB'\").show()\n",
    "trade_df.filter(f.col('OrderReferenceNumber')=='1000045252').show(10)\n",
    "trade_df_grouped.filter(f.col('OrderReferenceNumber')=='1000045252').show(10)\n",
    "nbbo_df.groupBy(\"Feed\",'f').count().show()\n",
    "# BL: https://www.sec.gov/comments/265-29/26529-11.pdf for context on UQDF vs CQS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T03:58:40.264643Z",
     "iopub.status.busy": "2024-03-05T03:58:40.264005Z",
     "iopub.status.idle": "2024-03-05T03:58:40.489329Z",
     "shell.execute_reply": "2024-03-05T03:58:40.488151Z",
     "shell.execute_reply.started": "2024-03-05T03:58:40.264602Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create the union of trades and nbbo data to simulate as-of join \n",
    "# normalize list of columns for trades_df and nbbo_df, initialize missing columns as nulls\n",
    "#we also add DataType column initialised as 1 for trades and 0 for nbbo to separate datasets\n",
    "trade_df_grouped=trade_df_grouped\\\n",
    "    .withColumn('BidPrice',f.lit(None).cast(t.NullType()))\\\n",
    "    .withColumn('BidQuantity',f.lit(None).cast(t.NullType()))\\\n",
    "    .withColumn('AskPrice',f.lit(None).cast(t.NullType()))\\\n",
    "    .withColumn('AskQuantity',f.lit(None).cast(t.NullType()))\\\n",
    "    .withColumn('DataType',f.lit(1).cast(t.IntegerType()))\n",
    "nbbo_df = nbbo_df.withColumn('vWAP',f.lit(None).cast(t.NullType()))\\\n",
    "    .withColumn('Quantity',f.lit(None).cast(t.NullType()))\\\n",
    "    .withColumn('Side',f.lit(None).cast(t.NullType()))\\\n",
    "    .withColumn('DataType',f.lit(0).cast(t.IntegerType()))\n",
    "\n",
    "#union both dataframes, and make sure the names are order of columns are identical\n",
    "#BL: i added Feed and f as helps to create a story later\n",
    "select_cols = [\"Feed\",\"f\",'Product','dtHour','vWAP','Quantity','Side','BidPrice','BidQuantity','AskPrice','AskQuantity','ReceiptTimestamp','DataType','dtHour','dt']\n",
    "union_df = trade_df_grouped.select(select_cols)\\\n",
    ".union(nbbo_df.select(select_cols))\n",
    "union_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T13:23:14.672558Z",
     "iopub.status.busy": "2024-03-04T13:23:14.672166Z",
     "iopub.status.idle": "2024-03-04T13:23:14.698788Z",
     "shell.execute_reply": "2024-03-04T13:23:14.697603Z",
     "shell.execute_reply.started": "2024-03-04T13:23:14.672519Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "#we are looking for the closest timestamp to the current row. \n",
    "lookup_window=Window.partitionBy('Product').orderBy(\"Feed\",\"f\",'ReceiptTimestamp','DataType').rowsBetween(Window.unboundedPreceding, Window.currentRow)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T19:40:33.696050Z",
     "iopub.status.busy": "2024-03-04T19:40:33.695006Z",
     "iopub.status.idle": "2024-03-04T20:33:11.205018Z",
     "shell.execute_reply": "2024-03-04T20:33:11.203741Z",
     "shell.execute_reply.started": "2024-03-04T19:40:33.696007Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# caclulate the price difference based on Nbbo midpoint\n",
    "where_list=\"','\".join(sample_tickers)\n",
    "if False:\n",
    "    union_df_price = union_df \\\n",
    "        .where(f\"Product in ('{where_list}')\")\\\n",
    "        .select('Feed','f','Product','vWAP','Quantity','Side','ReceiptTimestamp','dtHour','dt',\n",
    "        f.last('AskPrice', True).over(lookup_window).alias('AskPriceNbbo'),\n",
    "        f.last('BidPrice', True).over(lookup_window).alias('BidPriceNbbo'),\n",
    "        f.last(f.when(f.col('DataType') < 1, f.col('ReceiptTimestamp') ).otherwise(None), True).over(lookup_window).alias('TimestampNbbo')        \n",
    "        )\\\n",
    "        .withColumn('MidPrice', (f.col('AskPriceNbbo') + f.col('BidPriceNbbo'))/2)\\\n",
    "        .withColumn('ArrivalPriceImprovementBP', ((f.col('vWAP') -f.col('MidPrice'))/f.col('MidPrice') )*1000).filter(f.col('AskPrice').isNull()).cache()\n",
    "else:\n",
    "    union_df_price = union_df \\\n",
    "        .select('Feed','f','Product','vWAP','Quantity','Side','ReceiptTimestamp','dtHour','dt',\n",
    "        f.last('AskPrice', True).over(lookup_window).alias('AskPriceNbbo'),\n",
    "        f.last('BidPrice', True).over(lookup_window).alias('BidPriceNbbo'),\n",
    "        f.last(f.when(f.col('DataType') < 1, f.col('ReceiptTimestamp') ).otherwise(None), True).over(lookup_window).alias('TimestampNbbo')        \n",
    "        )\\\n",
    "        .withColumn('MidPrice', (f.col('AskPriceNbbo') + f.col('BidPriceNbbo'))/2)\\\n",
    "        .withColumn('ArrivalPriceImprovementBP', ((f.col('vWAP') -f.col('MidPrice'))/f.col('MidPrice') )*1000).filter(f.col('AskPrice').isNull()).cache()\n",
    "    \n",
    "union_df_price\n",
    "if False:\n",
    "    union_partition_columns=['dt','Product']\n",
    "    union_df_price.repartition(*union_partition_columns).write.partitionBy(*union_partition_columns)\\\n",
    "            .mode('overwrite').parquet(f\"{s3_working_dir}/price_trade_df.parquet\")\n",
    "union_df_price=spark.read.parquet(f\"{s3_working_dir}/price_trade_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T20:33:11.207933Z",
     "iopub.status.busy": "2024-03-04T20:33:11.207327Z",
     "iopub.status.idle": "2024-03-04T20:34:03.869306Z",
     "shell.execute_reply": "2024-03-04T20:34:03.868149Z",
     "shell.execute_reply.started": "2024-03-04T20:33:11.207892Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#BL: please check if gap fill forward works properly and then we just remove filter on top to do this visual accross the board\n",
    "right_tale_limit = 500\n",
    "if True:\n",
    "    arrival_price_stats_pd=union_df_price.groupby('dtHour','Feed','f','Product').agg(f.mean('ArrivalPriceImprovementBP').alias('AvgArrivalPriceImprovementBP'))\\\n",
    "    .where(\"AvgArrivalPriceImprovementBP is not null\").toPandas()\n",
    "    \n",
    "arrival_price_stats_less_oiutliers_pd=arrival_price_stats_pd.query(f\"AvgArrivalPriceImprovementBP<{right_tale_limit}\")\n",
    "#arrival_price_stats_pd.groupby('Product').agg(f.mean('AvgArrivalPriceImprovementBP').alias('AvgArrivalPriceImprovementBP')).pandas_api()[[\"AvgArrivalPriceImprovementBP\"]].astype(float).hist()\n",
    "def graph_hist(l_df,l_title,bins=100,figsize=(6,2)):\n",
    "    l_df.hist(bins=bins,figsize=figsize);plt.title(l_title);\n",
    "    plt.suptitle('').set_visible(False)\n",
    "graph_hist((arrival_price_stats_pd[['AvgArrivalPriceImprovementBP']].astype(float)),\"Average Arrival Price Improvement\")\n",
    "graph_hist(arrival_price_stats_less_oiutliers_pd[['AvgArrivalPriceImprovementBP']].astype(float),\"Average Arrival Price Improvement(no outliers)\")\n",
    "graph_hist(arrival_price_stats_pd.groupby('Product').agg(AvgArrivalPriceImprovementBP=(\"AvgArrivalPriceImprovementBP\",\"mean\")),\"Average Arrival Price Improvement by single name\")\n",
    "graph_hist(arrival_price_stats_less_oiutliers_pd.groupby('Product').agg(AvgArrivalPriceImprovementBP=(\"AvgArrivalPriceImprovementBP\",\"mean\")),\"Average Arrival Price Improvement by single name (no outliers)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T20:34:03.871071Z",
     "iopub.status.busy": "2024-03-04T20:34:03.870726Z",
     "iopub.status.idle": "2024-03-04T20:34:08.711340Z",
     "shell.execute_reply": "2024-03-04T20:34:08.710026Z",
     "shell.execute_reply.started": "2024-03-04T20:34:03.871032Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,4));sns.histplot(arrival_price_stats_less_oiutliers_pd, x='AvgArrivalPriceImprovementBP', hue='dtHour',multiple='dodge', shrink=.75, bins=20)\\\n",
    ".set_title('Average Arrival Price Improvement - by hour of the day');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T20:34:08.715338Z",
     "iopub.status.busy": "2024-03-04T20:34:08.714739Z",
     "iopub.status.idle": "2024-03-04T20:34:12.446886Z",
     "shell.execute_reply": "2024-03-04T20:34:12.445558Z",
     "shell.execute_reply.started": "2024-03-04T20:34:08.715298Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,4));sns.histplot(arrival_price_stats_less_oiutliers_pd, x='AvgArrivalPriceImprovementBP', hue='Feed',multiple='dodge', shrink=.75, bins=20)\\\n",
    ".set_title('Average Arrival Price Improvement - by Feed');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T20:34:12.448731Z",
     "iopub.status.busy": "2024-03-04T20:34:12.448374Z",
     "iopub.status.idle": "2024-03-04T20:34:17.028925Z",
     "shell.execute_reply": "2024-03-04T20:34:17.027623Z",
     "shell.execute_reply.started": "2024-03-04T20:34:12.448691Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,4));sns.histplot(arrival_price_stats_less_oiutliers_pd, x='AvgArrivalPriceImprovementBP', hue='f',multiple='dodge', shrink=.75, bins=20)\\\n",
    ".set_title('Average Arrival Price Improvement - by \"f\"');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T03:40:16.501047Z",
     "iopub.status.busy": "2024-03-05T03:40:16.500398Z",
     "iopub.status.idle": "2024-03-05T03:40:50.492190Z",
     "shell.execute_reply": "2024-03-05T03:40:50.490959Z",
     "shell.execute_reply.started": "2024-03-05T03:40:16.501006Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pick few orders to sample to simulate \"your own\" trades\n",
    "#trade_df.filter(f.col('OrderReferenceNumber')=='1000045252').show(10)\n",
    "lookback_offset=1*1000*1000*1000*60\n",
    "trade_stats_df=trade_df.where(\"OrderReferenceNumber is not null and OrderReferenceNumber != 0 and Product='AMZN'\")\\\n",
    ".groupBy('OrderReferenceNumber',\"Product\",\"Feed\",'f','dt','Side').agg(f.count('ReceiptTimestamp').alias('partial_count'),\n",
    "                                                                  f.min('ReceiptTimestamp').alias('fill_start'),\n",
    "                                                                  f.max('ReceiptTimestamp').alias('fill_end')\n",
    "                                                                 )\\\n",
    ".select(\"*\",\n",
    "        f.round((f.col(\"fill_end\")-f.col(\"fill_start\"))/1000/1000/1000/60,1).alias('fill_duration_min'),\n",
    "        (f.col('fill_start')-lookback_offset).alias('ts_start'),\n",
    "        (f.col('fill_end')+lookback_offset).alias('ts_end')\n",
    "       ).where(\"fill_duration_min>1 and partial_count>20\")\n",
    "print(trade_stats_df.count())\n",
    "trade_stats_df.orderBy('partial_count','fill_duration_min',ascending=False).orderBy(\"OrderReferenceNumber\").show()\n",
    "sample_trades=trade_stats_df.drop('fill_start','fill_end','SequenceNumber').join(trade_df.drop('SequenceNumber'),on=['OrderReferenceNumber',\"Product\",'dt','Feed','f'])\n",
    "sample_trades_dict=trade_stats_df.orderBy(\"OrderReferenceNumber\").collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T03:40:50.494542Z",
     "iopub.status.busy": "2024-03-05T03:40:50.494194Z",
     "iopub.status.idle": "2024-03-05T03:40:50.504777Z",
     "shell.execute_reply": "2024-03-05T03:40:50.503578Z",
     "shell.execute_reply.started": "2024-03-05T03:40:50.494504Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "where_list=[]\n",
    "for one_trade_det in sample_trades_dict:\n",
    "    product,ts_s,ts_e=one_trade_det['Product'],one_trade_det['ts_start'],one_trade_det['ts_end']\n",
    "    where_list.append(f\"Product=='{product}' and (ReceiptTimestamp between {ts_s} and  {ts_e}) \")\n",
    "where_text = \"(\"+') OR ('.join(where_list)+\")\"\n",
    "where_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T03:40:50.506492Z",
     "iopub.status.busy": "2024-03-05T03:40:50.506154Z",
     "iopub.status.idle": "2024-03-05T03:41:37.399475Z",
     "shell.execute_reply": "2024-03-05T03:41:37.398123Z",
     "shell.execute_reply.started": "2024-03-05T03:40:50.506454Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nbbo_sample_pd  = nbbo_df.where(where_text).toPandas()\n",
    "sample_trades_pd=sample_trades.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T03:41:37.403087Z",
     "iopub.status.busy": "2024-03-05T03:41:37.402501Z",
     "iopub.status.idle": "2024-03-05T03:41:37.739494Z",
     "shell.execute_reply": "2024-03-05T03:41:37.738258Z",
     "shell.execute_reply.started": "2024-03-05T03:41:37.403048Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_trade_price_pd  = sample_trades_pd.set_index('ReceiptTimestamp')[['OrderReferenceNumber','Side','Price','dt','ts_start','ts_end']].join(nbbo_sample_pd.set_index('ReceiptTimestamp')[['BidPrice','AskPrice','dt']],how='outer',lsuffix='_tr', rsuffix='_nb').sort_index()\n",
    "sample_trade_price_pd['BidPrice']=np.where(sample_trade_price_pd['dt_nb'].astype(str) < '2022-06-06' , sample_trade_price_pd['BidPrice'].astype(float)/20,sample_trade_price_pd['BidPrice'].astype(float))\n",
    "sample_trade_price_pd['AskPrice']=np.where(sample_trade_price_pd['dt_nb'].astype(str) < '2022-06-06' , sample_trade_price_pd['AskPrice'].astype(float)/20,sample_trade_price_pd['AskPrice'].astype(float))\n",
    "sample_trade_price_pd['Price']=np.where(sample_trade_price_pd['dt_tr'].astype(str) < '2022-06-06' , sample_trade_price_pd['Price'].astype(float)/20,sample_trade_price_pd['Price'].astype(float))\n",
    "\n",
    "\n",
    "sample_trade_price_pd['BidPrice']=sample_trade_price_pd['BidPrice'].fillna(method='ffill').fillna(method='bfill')\n",
    "sample_trade_price_pd['AskPrice']=sample_trade_price_pd['AskPrice'].fillna(method='ffill').fillna(method='bfill')\n",
    "sample_trade_price_pd['Price']=sample_trade_price_pd['Price'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T04:08:28.098246Z",
     "iopub.status.busy": "2024-03-05T04:08:28.097600Z",
     "iopub.status.idle": "2024-03-05T04:08:31.478650Z",
     "shell.execute_reply": "2024-03-05T04:08:31.477514Z",
     "shell.execute_reply.started": "2024-03-05T04:08:28.098206Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10,3)\n",
    "for one_ord in sample_trade_price_pd[['OrderReferenceNumber','ts_start','ts_end','dt_tr']].drop_duplicates().dropna().iterrows():\n",
    "    ord_ref = one_ord[1].OrderReferenceNumber\n",
    "    ts_start = (one_ord[1].ts_start)\n",
    "    ts_end = (one_ord[1].ts_end)\n",
    "    dt_tr = (one_ord[1].dt_tr)\n",
    "    one_pd = sample_trade_price_pd.query(f\"ReceiptTimestamp>={ts_start}\").query(f\"ReceiptTimestamp<={ts_end}\")\n",
    "    plot_title = f\"{ord_ref} executed on {dt_tr} at {one_pd['Side'].drop_duplicates().dropna().values[0][0]}\"\n",
    "    #one_pd[['BidPrice','Price','AskPrice']].plot(figsize=(10,3),title=plot_title)\n",
    "    plt.plot(one_pd.index,one_pd['BidPrice'], marker='', color='green', linewidth=1, label=\"BID\")\n",
    "    plt.plot(one_pd.index,one_pd['AskPrice'], marker='', color='red', linewidth=1, label=\"ASK\")\n",
    "    plt.plot(one_pd.index,one_pd['Price'], marker='*', color='blue', linewidth=0, label=\"ASK\")\n",
    "    plt.legend()\n",
    "    plt.title(plot_title)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T03:54:01.437793Z",
     "iopub.status.busy": "2024-03-05T03:54:01.437141Z",
     "iopub.status.idle": "2024-03-05T03:54:07.248982Z",
     "shell.execute_reply": "2024-03-05T03:54:07.247615Z",
     "shell.execute_reply.started": "2024-03-05T03:54:01.437754Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trade_df\\\n",
    ".withColumn('ReceiptTimestampEST',f.from_utc_timestamp(f.from_unixtime(f.col('ReceiptTimestamp').cast(t.StringType())[0:10]),'America/New_York'))\\\n",
    ".withColumn('ReceiptTimestampESTDay',f.date_format(f.col('ReceiptTimestampEST'),'yyyy-MM-dd'))\\\n",
    ".withColumn('ReceiptTimestampESTTime',f.date_format(f.col('ReceiptTimestampEST'),'HH:mm:ss'))\\\n",
    ".withColumn('ReceiptTimestampESTWorkingHours',f.when( (f.col('ReceiptTimestampESTTime')>='09:30:00') & (f.col('ReceiptTimestampESTTime')<'16:00:00'), 1).otherwise(0)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T03:58:40.491435Z",
     "iopub.status.busy": "2024-03-05T03:58:40.490782Z",
     "iopub.status.idle": "2024-03-05T03:58:40.555096Z",
     "shell.execute_reply": "2024-03-05T03:58:40.553859Z",
     "shell.execute_reply.started": "2024-03-05T03:58:40.491395Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculate price difference vs Close\n",
    "#adding necessary time columns\n",
    "trade_df_grouped = trade_df_grouped\\\n",
    ".withColumn('ReceiptTimestampEST',f.from_utc_timestamp(f.from_unixtime(f.col('ReceiptTimestamp').cast(t.StringType())[0:10]),'America/New_York'))\\\n",
    ".withColumn('ReceiptTimestampESTDay',f.date_format(f.col('ReceiptTimestampEST'),'yyyy-MM-dd'))\\\n",
    ".withColumn('ReceiptTimestampESTTime',f.date_format(f.col('ReceiptTimestampEST'),'HH:mm:ss'))\\\n",
    ".withColumn('ReceiptTimestampESTWorkingHours',f.when( (f.col('ReceiptTimestampESTTime')>='09:30:00') & (f.col('ReceiptTimestampESTTime')<'16:00:00'), 1).otherwise(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T03:58:40.558415Z",
     "iopub.status.busy": "2024-03-05T03:58:40.557815Z",
     "iopub.status.idle": "2024-03-05T03:58:40.565532Z",
     "shell.execute_reply": "2024-03-05T03:58:40.564246Z",
     "shell.execute_reply.started": "2024-03-05T03:58:40.558375Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trade_df_grouped.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T03:58:40.567753Z",
     "iopub.status.busy": "2024-03-05T03:58:40.567028Z",
     "iopub.status.idle": "2024-03-05T03:59:02.107742Z",
     "shell.execute_reply": "2024-03-05T03:59:02.106390Z",
     "shell.execute_reply.started": "2024-03-05T03:58:40.567711Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define window\n",
    "daily_window=Window.partitionBy('Product','ReceiptTimestampESTDay','Side').orderBy('ReceiptTimestampEST').rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)\n",
    "\n",
    "#run aggregation to compare price improvements for AMZN stock\n",
    "#vs daily Close price \n",
    "#vs daily max price\n",
    "#vs daily max price during exchange working hours \n",
    "trade_df_grouped.filter((f.col('Side')==\"Bid\") | (f.col('Side')==\"Ask\")).filter(f.col('Product')=='AMZN').select(\n",
    "    'Product','Side','vWAP','ReceiptTimestampESTDay','ReceiptTimestampESTTime','ReceiptTimestampESTWorkingHours', \n",
    "    f.last(f.when(f.col('ReceiptTimestampESTWorkingHours')>0, f.col('vWAP')).otherwise(None),True).over(daily_window).alias('vWAPClose'),\n",
    "    f.max('vWAP').over(daily_window).alias('vWAPDaily'),\n",
    "    f.max(f.when(f.col('ReceiptTimestampESTWorkingHours')>0, f.col('vWAP')).otherwise(None)).over(daily_window).alias('vWAPDailyWorkingHours')                        \n",
    ").withColumn('ArrivalPriceImprovementBPvsClose', (f.col('vWAP') - f.col('vWAPClose'))*1000)\\\n",
    ".withColumn('ArrivalPriceImprovementBPvsDaily', (f.col('vWAP') - f.col('vWAPDaily'))*1000)\\\n",
    ".withColumn('ArrivalPriceImprovementBPvsDailyWH', (f.col('vWAP') - f.col('vWAPDailyWorkingHours'))*1000).show(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Kubernetes)",
   "language": "python",
   "name": "spark_python_kubernetes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
